{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KR Youtube Trending Videos Analysis\n",
    "This notebook will load the Korean Youtube Trending Videos Dataset from `data` folder, and then compute and save to file in the `results` folder the following variables:\n",
    "- Number of videos, channels and categories\n",
    "- Mean and standard deviation of the number of views, comments, likes and dislikes\n",
    "- Most popular categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import useful libraries and functions, then we load data from `data` folder in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country = KR\n",
       "numCountries = 3\n",
       "df = [video_id: string, trending_date: string ... 14 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[video_id: string, trending_date: string ... 14 more fields]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, Dataset, Row, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.util.matching\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val country = \"KR\"\n",
    "val numCountries = 3\n",
    "val df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/\" + country + \"videos_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the first two lines of the DataFrame (including header and the first data point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "��군...| 76533|  211|      28|          113|https://i.ytimg.c...|            FALSE|           FALSE|                 FALSE|[채널A단독]北 병사 현재 '의...|\n",
      "+-----------+-------------+-----------------------------+-------------+-----------+--------------------+----------------------------+------+-----+--------+-------------+--------------------+-----------------+----------------+----------------------+------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----------+-------------+-----------------------------+-------------+-----------+--------------------+----------------------------+------+-----+--------+-------------+--------------------+-----------------+----------------+----------------------+------------------------------+\n",
      "|   video_id|trending_date|                        title|channel_title|category_id|        publish_time|                        tags| views|likes|dislikes|comment_count|      thumbnail_link|comments_disabled|ratings_disabled|video_error_or_removed|                   description|\n",
      "+-----------+-------------+-----------------------------+-------------+-----------+--------------------+----------------------------+------+-----+--------+-------------+--------------------+-----------------+----------------+----------------------+------------------------------+\n",
      "|RxGQe4EeEpA|     17.14.11|좋아 by 민서_윤종신_좋니 답가| 라푸마코리아|         22|2017-11-13T07:07:...|\"라푸마|\"\"윤종신\"\"|\"\"좋니...|156130| 1422|      40|          272|https://i.ytimg.c...|            FALSE|           FALSE|                 FALSE|윤종신 '좋니'의 답가 '좋아'...|\n",
      "|hH7wVE8OlQ0|     17.14.11|    JSA 귀순 북한군 총격 부상|       Edward|         25|2017-11-13T10:59:...|   \"JSA|\"\"귀순\"\"|\"\"북�"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compute the number of channels, videos and categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nChannels = 4044\n",
       "nVideos = 36730\n",
       "nCategories = 18\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nChannels = df.select(\"channel_title\").distinct.count\n",
    "val nVideos = df.count\n",
    "val nCategories = df.select(\"category_id\").distinct.count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the mean and standard deviation of the number of views, comments, likes and dislikes.\n",
    "\n",
    "We use the function `df.describe()` then transform the results from `double` to `integer` type, in order to remove the decimals.\n",
    "Finally we filter out the values of max, min and number of videos, which are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------+------+--------+\n",
      "|summary|  views|comment_count| likes|dislikes|\n",
      "+-------+-------+-------------+------+--------+\n",
      "|   mean| 424947|         2025| 12186|     539|\n",
      "| stddev|2430637|        21506|117053|   13708|\n",
      "+-------+-------+-------------+------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numDataDouble = [summary: string, views: string ... 3 more fields]\n",
       "numData = [summary: string, views: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[summary: string, views: int ... 3 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Compute mean, stddev, max and min values of likes, dislikes, views and comment_count\n",
    "val numDataDouble = df.describe(\"views\", \"comment_count\", \"likes\", \"dislikes\")\n",
    "\n",
    "val numData = numDataDouble.withColumn(\"views\", col(\"views\").cast(IntegerType))\n",
    "                           .withColumn(\"likes\", col(\"likes\").cast(IntegerType))\n",
    "                           .withColumn(\"dislikes\", col(\"dislikes\").cast(IntegerType))\n",
    "                           .withColumn(\"comment_count\", col(\"comment_count\").cast(IntegerType))\n",
    "                           .filter($\"summary\" =!= \"max\")\n",
    "                           .filter($\"summary\" =!= \"min\")\n",
    "                           .filter($\"summary\" =!= \"count\")\n",
    "//val numDataLong = numData.select(numData.columns.map(c => col(c).cast(IntegerType)) : _*)\n",
    "numData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the most popular channels by grouping the dataset according to channels, and then ordering the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|           channel_title|num_videos|\n",
      "+------------------------+----------+\n",
      "|                    null|      2163|\n",
      "|                신의한수|       222|\n",
      "|                정규재TV|       219|\n",
      "|              도봉박홍기|       218|\n",
      "|                 보겸 TV|       195|\n",
      "|               JTBC News|       182|\n",
      "|       윤창중칼럼세상 TV|       178|\n",
      "|       철구형 (CHULTUBE)|       167|\n",
      "|영국남자 Korean Engli...|       163|\n",
      "|                    밴쯔|       162|\n",
      "+------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "groupedByChannel = RelationalGroupedDataset: [grouping expressions: [channel_title: string], value: [video_id: string, trending_date: string ... 14 more fields], type: GroupBy]\n",
       "channelsVideoCount = [channel_title: string, num_videos: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[channel_title: string, num_videos: bigint]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val groupedByChannel = df.groupBy(\"channel_title\")\n",
    "val channelsVideoCount = groupedByChannel.count()\n",
    "                .withColumnRenamed(\"count\", \"num_videos\")\n",
    "                .orderBy(desc(\"num_videos\"))\n",
    "channelsVideoCount.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compute the most popular categories by grouping the dataset according to categories, and then ordering the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|category_id|num_videos|\n",
      "+-----------+----------+\n",
      "|         24|      8955|\n",
      "|         25|      7582|\n",
      "|         22|      7056|\n",
      "|          1|      2200|\n",
      "|       null|      2163|\n",
      "|         23|      2056|\n",
      "|         10|      1825|\n",
      "|         20|      1392|\n",
      "|         17|       936|\n",
      "|         15|       735|\n",
      "+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "groupedByCategory = RelationalGroupedDataset: [grouping expressions: [category_id: string], value: [video_id: string, trending_date: string ... 14 more fields], type: GroupBy]\n",
       "categoriesVideoCount = [category_id: string, num_videos: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[category_id: string, num_videos: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val groupedByCategory = df.groupBy(\"category_id\")\n",
    "val categoriesVideoCount = groupedByCategory.count()\n",
    "                .withColumnRenamed(\"count\", \"num_videos\")\n",
    "                .orderBy(desc(\"num_videos\"))\n",
    "categoriesVideoCount.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data contained in the `.json` file, with the category ids, matched with the corresponding category names.\n",
    "\n",
    "The `.json` file has a complex structure, which makes it necessary to perform many steps to polish the data and obtain what we need as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|            name|\n",
      "+---+----------------+\n",
      "|  1|Film & Animation|\n",
      "|  2|Autos & Vehicles|\n",
      "| 10|           Music|\n",
      "| 15|  Pets & Animals|\n",
      "| 17|          Sports|\n",
      "+---+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "categoriesStruct = [etag: string, items: array<struct<etag:string,id:string,kind:string,snippet:struct<assignable:boolean,channelId:string,title:string>>> ... 1 more field]\n",
       "categoriesArray = Array(WrappedArray([\"XI7nbFXulYBIpL0ayR_gDh3eu1k/Xy1mB4_yLrHy_BmKmPBggty2mZQ\", 1, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Film & Animation]], \" [\"XI7nbFXulYBIpL0ayR_gDh3eu1k/UZ1oLIIz2dxIhO45ZTFR3a3NyTA\"\", 2, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Autos & Vehicles]], \" [\"XI7nbFXulYBIpL0ayR_gDh3eu1k/nqRIq97-xe5XRZTxbknKFVe5Lmg\"\", 10, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Music]], \" [\"XI7nbFXulYBIpL0ayR_gDh3eu1k/HwXKamM1Q20q9BN-oBJavSGkfDI\"\", 15, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Pets...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(WrappedArray([\"XI7nbFXulYBIpL0ayR_gDh3eu1k/Xy1mB4_yLrHy_BmKmPBggty2mZQ\", 1, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Film & Animation]], \" [\"XI7nbFXulYBIpL0ayR_gDh3eu1k/UZ1oLIIz2dxIhO45ZTFR3a3NyTA\"\", 2, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Autos & Vehicles]], \" [\"XI7nbFXulYBIpL0ayR_gDh3eu1k/nqRIq97-xe5XRZTxbknKFVe5Lmg\"\", 10, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Music]], \" [\"XI7nbFXulYBIpL0ayR_gDh3eu1k/HwXKamM1Q20q9BN-oBJavSGkfDI\"\", 15, youtube#videoCategory, [true, UCBR8-60-B28hp2BmDPdntcQ, Pets..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Load categories names file data\n",
    "val categoriesStruct = spark.read.option(\"multiline\",\"true\")\n",
    "                .json(\"data/\" + country + \"_category_id.json\")\n",
    "// extract the array inside the struct and convert to string\n",
    "val categoriesArray = categoriesStruct.collect()(0)(1)\n",
    "                .toString.split(\",\")\n",
    "// extract categories names and ids\n",
    "val names = categoriesArray.filter(x => x.contains(\"]]\")).map(x => x.dropRight(2))\n",
    "val ids = categoriesArray.filter(x => x.length() < 3)\n",
    "// create a DataFrame out of category ids and names\n",
    "val categoriesNames = sc.parallelize(ids zip names).toDF(\"id\", \"name\")\n",
    "\n",
    "categoriesNames.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can join the two DataFrames of top categories and categories names, obtaining a DataFrame containing only categories names and number of videos belonging to that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                name|num_videos|\n",
      "+--------------------+----------+\n",
      "|       Entertainment|      8955|\n",
      "|     News & Politics|      7582|\n",
      "|      People & Blogs|      7056|\n",
      "|    Film & Animation|      2200|\n",
      "|              Comedy|      2056|\n",
      "|               Music|      1825|\n",
      "|              Gaming|      1392|\n",
      "|              Sports|       936|\n",
      "|      Pets & Animals|       735|\n",
      "|       Howto & Style|       558|\n",
      "|           Education|       486|\n",
      "|               Shows|       165|\n",
      "|    Autos & Vehicles|       120|\n",
      "|Science & Technology|       115|\n",
      "|     Travel & Events|        96|\n",
      "|           Trailers]|         2|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topCategories = [name: string, num_videos: bigint]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[name: string, num_videos: bigint]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// join the dataframes so the categories are matched with their names\n",
    "val topCategories = categoriesVideoCount.join(categoriesNames, categoriesVideoCount(\"category_id\") === categoriesNames(\"id\"), \"leftouter\")\n",
    "                    .orderBy(desc(\"num_videos\"))\n",
    "                    .select(\"name\", \"num_videos\")\n",
    "                    .filter($\"name\" =!= \"null\")\n",
    "\n",
    "// hide the numeric column in the output.\n",
    "topCategories.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed all the data we need, we can create a single-line DataFrame containing the data for this country.\n",
    "\n",
    "We need to transform DataFrames into Lists, which is a structure that enable us to extract single values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+----------+--------------+----------+------------+-------------+---------------+----------+------------+-------------+---------------+---------------+--------------+----------------+----------+----------+----------+----------+--------------+-------------+-----------+\n",
      "|country|num_channels|num_videos|num_categories|views_mean|views_stddev|comments_mean|comments_stddev|likes_mean|likes_stddev|dislikes_mean|dislikes_stddev|     1_category|    2_category|      3_category|4_category|5_category|6_category|7_category|    8_category|   9_category|10_category|\n",
      "+-------+------------+----------+--------------+----------+------------+-------------+---------------+----------+------------+-------------+---------------+---------------+--------------+----------------+----------+----------+----------+----------+--------------+-------------+-----------+\n",
      "|     KR|        4044|     36730|            18|    424947|     2430637|         2025|          21506|     12186|      117053|          539|          13708|News & Politics|People & Blogs|Film & Animation|    Comedy|     Music|    Gaming|    Sports|Pets & Animals|Howto & Style|  Education|\n",
      "+-------+------------+----------+--------------+----------+------------+-------------+---------------+----------+------------+-------------+---------------+---------------+--------------+----------------+----------+----------+----------+----------+--------------+-------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numDataList = List([mean,424947,2025,12186,539], [stddev,2430637,21506,117053,13708])\n",
       "topCategoriesList = List([Entertainment,8955], [News & Politics,7582], [People & Blogs,7056], [Film & Animation,2200], [Comedy,2056], [Music,1825], [Gaming,1392], [Sports,936], [Pets & Animals,735], [Howto & Style,558], [Education,486], [Shows,165], [Autos & Vehicles,120], [Science & Technology,115], [Travel & Events,96], [Trailers],2])\n",
       "statsSeq = List((KR,4044,36730,18,424947,2430637,2025,21506,12186,117053,539,13708,News & Politics,People & Blogs,Film & Anim...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((KR,4044,36730,18,424947,2430637,2025,21506,12186,117053,539,13708,News & Politics,People & Blogs,Film & Anim..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numDataList = numData.rdd.collect().toList\n",
    "val topCategoriesList = topCategories.rdd.collect().toList\n",
    "\n",
    "val statsSeq = Seq((country, nChannels.toString, \n",
    "        nVideos.toString, nCategories.toString,\n",
    "        numDataList(0)(1).toString, numDataList(1)(1).toString,\n",
    "        numDataList(0)(2).toString, numDataList(1)(2).toString,\n",
    "        numDataList(0)(3).toString, numDataList(1)(3).toString,\n",
    "        numDataList(0)(4).toString, numDataList(1)(4).toString,\n",
    "        topCategoriesList(1)(0).toString, topCategoriesList(2)(0).toString,\n",
    "        topCategoriesList(3)(0).toString, topCategoriesList(4)(0).toString,\n",
    "        topCategoriesList(5)(0).toString, topCategoriesList(6)(0).toString,\n",
    "        topCategoriesList(7)(0).toString, topCategoriesList(8)(0).toString,\n",
    "        topCategoriesList(9)(0).toString, topCategoriesList(10)(0).toString))\n",
    "\n",
    "val statsRDD = spark.sparkContext.parallelize(statsSeq)\n",
    "val statsDF = statsRDD.toDF(\"country\", \"num_channels\", \n",
    "                            \"num_videos\", \"num_categories\",\n",
    "                            \"views_mean\", \"views_stddev\",\n",
    "                            \"comments_mean\", \"comments_stddev\",\n",
    "                            \"likes_mean\", \"likes_stddev\",\n",
    "                            \"dislikes_mean\", \"dislikes_stddev\",\n",
    "                            \"1_category\", \"2_category\", \n",
    "                            \"3_category\", \"4_category\",\n",
    "                            \"5_category\", \"6_category\", \n",
    "                            \"7_category\", \"8_category\",\n",
    "                            \"9_category\", \"10_category\")\n",
    "statsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allCountriesData = [country: string, num_channels: string ... 20 more fields]\n",
       "newAllCountriesData = [country: string, num_channels: string ... 20 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[country: string, num_channels: string ... 20 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val allCountriesData = spark.read.format(\"csv\")\n",
    "                .option(\"header\", \"true\")\n",
    "                .load(\"results/partial_\" + numCountries.toString)\n",
    "val newAllCountriesData = allCountriesData.union(statsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the final DataFrame to file, in the `results` folder.\n",
    "\n",
    "We use the function `repartition(1)` in order to generate only one file, instead of separating the data into several different files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newAllCountriesData.repartition(1)\n",
    "             .write\n",
    "             .format(\"csv\")\n",
    "             .option(\"header\", \"true\")\n",
    "             .save(\"results/partial_\" + (numCountries + 1).toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
