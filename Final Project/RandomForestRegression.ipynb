{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest Regression for Likes\n",
    "\n",
    "This notebook will train a vanilla Random Forest Regression model in order to predict the number of `likes` using the numbers of `views`, `comments`, `dislikes` and the `category_id` of each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.{DataFrame, Dataset, Row, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import scala.util.matching\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import org.apache.spark.ml.regression.RandomForestRegressionModel\n",
    "import org.apache.spark.ml.regression.RandomForestRegressor\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.feature.VectorIndexer\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import org.apache.spark.ml.feature.Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val country = \"US\"\n",
    "val usDF = spark.read.format(\"csv\").option(\"header\", \"true\")\n",
    "                .load(\"new\" + country + \"videos.csv\")\n",
    "usDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val usDF1 = usDF.select($\"category_id\"\n",
    "                        ,$\"comment_count\",$\"dislikes\",$\"views\",$\"likes\")\n",
    "                        .na.drop()\n",
    "\n",
    "\n",
    "usDF1.printSchema()\n",
    "\n",
    "val usDF2 = usDF1.withColumn(\"category_id\",col(\"category_id\").cast(DoubleType))\n",
    "    .withColumn(\"comment_count\",col(\"comment_count\").cast(IntegerType))\n",
    "    .withColumn(\"dislikes\",col(\"dislikes\").cast(IntegerType))\n",
    "    .withColumn(\"views\",col(\"views\").cast(IntegerType))\n",
    "    .withColumn(\"likes\",col(\"likes\").cast(IntegerType))\n",
    "usDF2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val numNan = usDF.count - usDF1.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val assembler = new VectorAssembler()\n",
    "                .setInputCols(Array(\"comment_count\",\n",
    "                                    \"dislikes\",\"views\",\n",
    "                                    \"category_id\"))\n",
    "                .setOutputCol(\"features\")\n",
    "                .transform(usDF2)\n",
    "usDF2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assembler.select($\"likes\",$\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val normalizer= new Normalizer()\n",
    "                .setInputCol(\"features\")\n",
    "                .setOutputCol(\"normfeatures\")\n",
    "                .setP(2.0)\n",
    "                .transform(assembler)\n",
    "normalizer.show(5)\n",
    "normalizer.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val featureIndexer = new VectorIndexer()\n",
    "  .setInputCol(\"likes\")\n",
    "  .setOutputCol(\"normfeatures\")\n",
    "  .setMaxCategories(4)\n",
    "  .fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val Array(trainingData,testData)= normalizer.randomSplit(Array(0.7,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rf = new RandomForestRegressor()\n",
    "  .setLabelCol(\"likes\")\n",
    "  .setFeaturesCol(\"normfeatures\")\n",
    "\n",
    "// Chain indexer and forest in a Pipeline.\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(featureIndexer, rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Train model. This also runs the indexer.\n",
    "val rfModel = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val resultDF = rfModel.transform(testData)\n",
    "            .select(\"likes\", \"prediction\")\n",
    "resultDF.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainingSummary = rfModel.summary\n",
    "println(s\"numIterations: ${trainingSummary.totalIterations}\")\n",
    "println(s\"objectiveHistory: [${trainingSummary.objectiveHistory.mkString(\",\")}]\")\n",
    "trainingSummary.residuals.show()\n",
    "println(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\n",
    "println(s\"r2: ${trainingSummary.r2}\")\n",
    "resultDF.describe().show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
